###Hadoop

구글의 검색 엔진 향상을 위해 출범
- 2차 저장소와 메인 메모리를 잘 조합해서 인터넷 전체를 저장하고 인덱스를 만드는 것

Node:  수많은 컴퓨터를 묶는 클러스터링 시스템 개발

+ 컴퓨터끼리 연결할수록 하드웨어 고장 가능성 높아지므로 HA를 위해 높은 수준의 이중화 구축
+ 데이터는 비싸지 않은 상용 컴퓨터들 전체에 분산되어 저장

=> 클러스터의 모든 컴퓨터들이 로컬에 있는 웹의 일부를 병렬로 검색한 후 검색 결과를 모아 사용자에게 보여줌

이를 위해 클러스터링 하드웨어, 소프트웨어와 분산 스토리지 개발

인용 문헌
- MapReduce : 대규모 클러스터에서의 단순한 데이터 프로세싱
- 빅테이블 : 구조화된 데이터를 위한 분산 저장 시스템


Hadoop의 주요 컴포넌트
1. HDFS : 클러스터에 대규모 데이터 저장을 위한 파일 시스템
2. MapReduce : HDFS 내 데이터 처리를 위한 태스크 개발
3. YARN(Yet Another Resource Negotiator) : 클러스터의 리소스를 관리하고 실행을 위한 태스크 스케줄링

Map : 전체 클러스터에 걸쳐서 원본 데이터를 처리하고, 그것을 키-값쌍의 튜플로 매핑
Reduction : 이 튜플들을 합쳐서 맵리듀스 작업의 결과 생성

Map Reduce가 어떻게 수행되는가? 

하둡은 데이터를 몇 개의 노드에서 40k의 노드와 100k 이상의 코어를 가진 야후 클러스터에 이르기까지 일괄적으로 클러스터 노드에 분산

- 맵리듀스 작업 코드를 클러스터의 노드로 분산시키고 각 노드에서 병렬로 코드 실행
- 각 노드는 해당 노드에 저장된 데이터에 대해서만 처리
- Reduce : 모든 노드의 결과 취합


Yarn : 하둡의 YARN 툴을 실행시켜서 맵리듀스 작업이 사용하는 하둡 리소스를 관리하고 접근을 조정

-files
-mapper
-reducer
-input
-output

File system Counters
Job Counters
Map-Reduce Framework

하둡 : 디스크 기반의 데이터 처리, 디스크에서 데이터를 읽고, 데이터 처리 및 결과를 디스크에 다시 쓰는 디스크 기반 배치 처리에 적합

—> 많은 데이터 애플리케이션은 디스크를 많이 사용하는 오퍼레이션에서 낼 수 있는 성능 이상으로 더 좋은 성능을 요구
